<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width,initial-scale=1" />
  <title>Amanpreet S. Walia</title>
  <meta name="description" content="Amanpreet S. Walia — Computer Vision Research Engineer" />
  <style>
    :root{
      --bg:#ffffff;
      --text:#111827;
      --muted:#4b5563;
      --line:#e5e7eb;
      --link:#0b5fff;
      --max: 860px;
      --sans: ui-sans-serif, system-ui, -apple-system, Segoe UI, Roboto, Helvetica, Arial;
      --mono: ui-monospace, SFMono-Regular, Menlo, Monaco, Consolas, "Liberation Mono","Courier New", monospace;
    }
    *{box-sizing:border-box;}
    body{margin:0;background:var(--bg);color:var(--text);font-family:var(--sans);line-height:1.6;}
    a{color:var(--link);text-decoration:none;}
    a:hover{text-decoration:underline;}
    .wrap{max-width:var(--max);margin:0 auto;padding:40px 18px 64px;}
    header{padding-bottom:18px;border-bottom:1px solid var(--line);}
    h1{margin:0;font-size:34px;letter-spacing:-0.3px;}
    .subtitle{margin:8px 0 14px;color:var(--muted);max-width:75ch;}
    .links{display:flex;flex-wrap:wrap;gap:12px;color:var(--muted);font-size:14px;}
    .pill{display:inline-flex;gap:8px;align-items:center;padding:6px 10px;border:1px solid var(--line);border-radius:999px;}
    main{margin-top:22px;display:grid;grid-template-columns: 1fr;gap:22px;}
    section{padding-top:6px;}
    h2{margin:0 0 10px;font-size:14px;letter-spacing:.12em;text-transform:uppercase;color:var(--muted);}
    .item{padding:12px 0;border-top:1px solid var(--line);}
    .item:first-of-type{border-top:none;padding-top:0;}
    .row{display:flex;flex-wrap:wrap;justify-content:space-between;gap:10px;}
    .role{font-weight:700;}
    .date{color:var(--muted);font-size:14px;}
    ul{margin:8px 0 0 18px;padding:0;}
    li{margin:6px 0;}
    .tags{margin-top:10px;display:flex;flex-wrap:wrap;gap:8px;}
    .tag{font-family:var(--mono);font-size:12px;color:var(--muted);border:1px solid var(--line);padding:4px 8px;border-radius:999px;}
    footer{margin-top:34px;padding-top:18px;border-top:1px solid var(--line);color:var(--muted);font-size:13px;display:flex;justify-content:space-between;flex-wrap:wrap;gap:10px;}
    .small{font-size:13px;color:var(--muted);}
  </style>
</head>
<body>
  <div class="wrap">
    <header>
      <h1>Amanpreet S. Walia</h1>
      <p class="subtitle">
        Computer Vision Research Engineer focused on on-device imaging (HDR / Super-Resolution),
        model optimization, and mobile deployment (Qualcomm SNPE/DLC, quantization).
      </p>
      <div class="links">
        <span class="pill">Brampton, ON, Canada</span>
        <span class="pill"><a href="mailto:amanpreetwalia278@gmail.com">amanpreetwalia278@gmail.com</a></span>
        <span class="pill"><a href="https://github.com/amanwalia123" target="_blank" rel="noreferrer">github.com/amanwalia123</a></span>
        <span class="pill"><a href="https://www.linkedin.com/in/amanpreetwalia/" target="_blank" rel="noreferrer">linkedin.com/in/amanpreetwalia</a></span>
        <span class="pill"><a href="./resume.pdf">resume.pdf</a></span>
      </div>
    </header>

    <main>
      <section id="experience">
        <h2>Experience</h2>

        <div class="item">
          <div class="row">
            <div class="role">Computer Vision Research Engineer — Samsung Research America</div>
            <div class="date">Dec 2022 — Present</div>
          </div>
          <ul>
            <li>Deployed image enhancement models to Qualcomm devices by converting pipelines to SNPE/DLC and resolving operator/runtime constraints for production inference.</li>
            <li>Built and optimized Super-Resolution and HDR components focusing on on-device quality stability (artifact control, consistency across scenes) and runtime efficiency.</li>
            <li>Improved latency and memory footprint through deployment-oriented architecture changes and quantization workflows (AIMET).</li>
          </ul>
          <div class="tags">
            <span class="tag">PyTorch</span><span class="tag">SNPE/DLC</span><span class="tag">AIMET</span><span class="tag">Mobile CV</span>
          </div>
        </div>

        <div class="item">
          <div class="row">
            <div class="role">Computer Vision Researcher — Algolux</div>
            <div class="date">Aug 2021 — Dec 2022</div>
          </div>
          <ul>
            <li>Developed a self-supervised depth estimation approach for gated imaging that improved generalization and closed the gap with prior supervised baselines under real capture conditions.</li>
          </ul>
          <div class="tags">
            <span class="tag">Depth</span><span class="tag">Self-supervised</span><span class="tag">Gated Imaging</span>
          </div>
        </div>

        <div class="item">
          <div class="row">
            <div class="role">Machine Learning Engineer (Contract) — Huawei Canada</div>
            <div class="date">Mar 2021 — Aug 2021</div>
          </div>
          <ul>
            <li>Ported low-rank decomposed GPT-2/CPM-style models to Huawei NPU execution constraints; validated accuracy/performance trade-offs and integration readiness.</li>
          </ul>
          <div class="tags">
            <span class="tag">Compression</span><span class="tag">NPU</span><span class="tag">NLP</span>
          </div>
        </div>
      </section>

      <section id="publications">
        <h2>Publications</h2>
        <div class="item">
          <ul>
            <li><b>CVPR 2026 (Accepted):</b> <i>Face2Scene: Using Facial Degradation as an Oracle for Diffusion-Based Scene Restoration</i>.</li>
            <li><b>CVPR 2023:</b> <i>Gated Stereo: Joint Depth Estimation from Gated and Wide-Baseline Active Stereo Cues</i>. arXiv:2305.12955.</li>
            <li><b>CVPR 2022:</b> <i>Gated2Gated: Self-Supervised Depth Estimation from Gated Images</i>. arXiv:2112.02416.</li>
          </ul>
          <div class="tags">
            <a class="tag" href="https://arxiv.org/abs/2305.12955" target="_blank" rel="noreferrer">arXiv:2305.12955</a>
            <a class="tag" href="https://arxiv.org/abs/2112.02416" target="_blank" rel="noreferrer">arXiv:2112.02416</a>
          </div>
        </div>
      </section>

      <section id="patents">
        <h2>Patents</h2>
        <div class="item">
          <div class="row">
            <div class="role">Dual-camera Joint Denoising-Deblurring using Burst of Short and Long Exposure Images</div>
            <div class="date">2024</div>
          </div>
          <div class="small">
            Patent application: <a href="https://patents.google.com/patent/US20240311968A1/en" target="_blank" rel="noreferrer">US20240311968A1</a>
          </div>
        </div>
      </section>

      <section id="skills">
        <h2>Skills</h2>
        <div class="item">
          <div class="small"><b>Languages:</b> Python, C++, C, Java, MATLAB, SQL</div>
          <div class="small"><b>Tools:</b> PyTorch, OpenCV, Qualcomm SNPE/DLC, AIMET, TensorFlow, Keras</div>
          <div class="small"><b>Hardware:</b> Qualcomm Snapdragon, Jetson TX1, Huawei Atlas 200, Raspberry Pi</div>
        </div>
      </section>

      <section id="education">
        <h2>Education</h2>
        <div class="item">
          <div class="row">
            <div class="role">M.Sc. (Thesis), Computer Science — McGill University</div>
            <div class="date">2018 — 2021</div>
          </div>
          <div class="small">GPA: 3.90/4.00 • Thesis: Uncertainty in depth estimation using RGB-gated images</div>
        </div>
        <div class="item">
          <div class="row">
            <div class="role">B.Eng., Computer Engineering — York University</div>
            <div class="date">2013 — 2018</div>
          </div>
          <div class="small">GPA: 7.9/9.0</div>
        </div>
      </section>
    </main>

    <footer>
      <div>© <span id="year"></span> Amanpreet S. Walia</div>
      <div>Hosted on GitHub Pages</div>
    </footer>
  </div>

  <script>
    document.getElementById("year").textContent = new Date().getFullYear();
  </script>
</body>
</html>
